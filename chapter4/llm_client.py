import os
from openai import OpenAI
from dotenv import load_dotenv
from typing import List, Dict

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
load_dotenv()
# æœŸæœ›åœ¨ .env æˆ–ç¯å¢ƒä¸­å­˜åœ¨ä»¥ä¸‹å˜é‡ï¼ˆå¦‚æœªåœ¨æ„é€ å‡½æ•°æ˜¾å¼ä¼ å…¥æ—¶ä½¿ç”¨ï¼‰ï¼š
# - LLM_MODEL_IDï¼šè¦è°ƒç”¨çš„æ¨¡å‹æ ‡è¯†ï¼Œä¾‹å¦‚ "gpt-4o"ã€"gpt-4o-mini" æˆ–ç¬¬ä¸‰æ–¹æœåŠ¡çš„æ¨¡å‹å
# - LLM_API_KEYï¼šæœåŠ¡çš„è®¿é—®å¯†é’¥ï¼Œç”¨äºé‰´æƒ
# - LLM_BASE_URLï¼šå…¼å®¹ OpenAI æ¥å£çš„æœåŠ¡åœ°å€ï¼Œä¾‹å¦‚ "https://api.openai.com/v1" æˆ–ä½ è‡ªå»º/ä»£ç†æœåŠ¡
# - LLM_TIMEOUTï¼šç½‘ç»œè¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆå•ä½ï¼šç§’ï¼‰ï¼Œå¯é€‰ï¼Œé»˜è®¤ 60

class HelloAgentsLLM:
    """
    ä¸ºæœ¬ä¹¦ "Hello Agents" å®šåˆ¶çš„ LLM å®¢æˆ·ç«¯ã€‚
    - ç›®æ ‡ï¼šä»¥ç»Ÿä¸€çš„æ–¹å¼è°ƒç”¨å…¼å®¹ OpenAI Chat Completions æ¥å£çš„æœåŠ¡
    - é€‚é…ï¼šOpenAI å®˜æ–¹ã€ç¬¬ä¸‰æ–¹ä»£ç†ã€æœ¬åœ°éƒ¨ç½²ç­‰å…¼å®¹å®ç°
    - ç‰¹æ€§ï¼šé»˜è®¤å¯ç”¨æµå¼å“åº”ï¼ˆstream=Trueï¼‰ï¼Œè¾¹åˆ°è¾¹æ‰“å°å¹¶æ”¶é›†æ¨¡å‹è¾“å‡º
    - é…ç½®ï¼šä» .env æˆ–æ„é€ å‚æ•°è¯»å–æ¨¡å‹ IDã€API å¯†é’¥ã€æœåŠ¡åœ°å€ä¸è¶…æ—¶
    """
    def __init__(self, model: str = None, apiKey: str = None, baseUrl: str = None, timeout: int = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯ã€‚ä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦‚æœæœªæä¾›ï¼Œåˆ™ä»ç¯å¢ƒå˜é‡åŠ è½½ã€‚
        å‚æ•°è¯´æ˜ï¼š
        - modelï¼šæ¨¡å‹æ ‡è¯†ï¼ˆå¦‚ "gpt-4o-mini" æˆ–å…¶ä»–å…¼å®¹æ¨¡å‹åï¼‰
        - apiKeyï¼šæœåŠ¡è®¿é—®å¯†é’¥ï¼›ä¸æä¾›æ—¶å°†è¯»å–ç¯å¢ƒå˜é‡ LLM_API_KEY
        - baseUrlï¼šæœåŠ¡åœ°å€ï¼ˆå…¼å®¹ OpenAI æ¥å£ï¼‰ï¼›ä¸æä¾›æ—¶è¯»å– LLM_BASE_URL
        - timeoutï¼šè¯·æ±‚è¶…æ—¶ç§’æ•°ï¼›ä¸æä¾›æ—¶è¯»å– LLM_TIMEOUTï¼Œé»˜è®¤ 60
        """
        self.model = model or os.getenv("LLM_MODEL_ID")
        apiKey = apiKey or os.getenv("LLM_API_KEY")
        baseUrl = baseUrl or os.getenv("LLM_BASE_URL")
        timeout = timeout or int(os.getenv("LLM_TIMEOUT", 60))
        # é€šè¿‡ â€œå‚æ•°ä¼˜å…ˆï¼Œå…¶æ¬¡ç¯å¢ƒå˜é‡â€ çš„ç­–ç•¥ï¼Œæå‡çµæ´»æ€§ä¸å¤ç”¨æ€§
        # å¦‚æœå…³é”®é…ç½®ç¼ºå¤±ï¼Œå°½æ—©æŠ¥é”™ï¼Œæœ‰åŠ©äºå¿«é€Ÿå®šä½é—®é¢˜
        if not all([self.model, apiKey, baseUrl]):
            raise ValueError("æ¨¡å‹IDã€APIå¯†é’¥å’ŒæœåŠ¡åœ°å€å¿…é¡»è¢«æä¾›æˆ–åœ¨.envæ–‡ä»¶ä¸­å®šä¹‰ã€‚")

        # åˆå§‹åŒ– OpenAI Python å®¢æˆ·ç«¯ï¼š
        # - api_keyï¼šç”¨äºé‰´æƒ
        # - base_urlï¼šæŒ‡å‘å…¼å®¹ OpenAI æ¥å£çš„æœåŠ¡ç«¯ï¼ˆå®˜æ–¹æˆ–ç¬¬ä¸‰æ–¹ï¼‰
        # - timeoutï¼šè®¾ç½®ç½‘ç»œè¯·æ±‚è¶…æ—¶ï¼Œé¿å…è°ƒç”¨å¡æ­»
        self.client = OpenAI(api_key=apiKey, base_url=baseUrl, timeout=timeout)

    def think(self, messages: List[Dict[str, str]], temperature: float = 0) -> str:
        """
        è°ƒç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œæ€è€ƒï¼Œå¹¶è¿”å›å…¶å“åº”ã€‚
        å‚æ•°è¯´æ˜ï¼š
        - messagesï¼šå¯¹è¯æ¶ˆæ¯åˆ—è¡¨ï¼Œæ ¼å¼éœ€ç¬¦åˆ OpenAI Chat æ¥å£çº¦å®š
          ä¾‹å¦‚ï¼š
          [{"role": "system", "content": "..."},
           {"role": "user", "content": "..."}]
          role å¯ä¸º "system" / "user" / "assistant"
        - temperatureï¼šé‡‡æ ·æ¸©åº¦ï¼Œå€¼è¶Šé«˜è¶Šå‘æ•£ï¼›0 å€¼æ›´å¯æ§ã€æ›´ç¡®å®š
        """
        print(f"ğŸ§  æ­£åœ¨è°ƒç”¨ {self.model} æ¨¡å‹...")
        try:
            # å‘èµ· chat.completions è¯·æ±‚ï¼š
            # - modelï¼šé€‰æ‹©çš„æ¨¡å‹ ID
            # - messagesï¼šå¤šè½®å¯¹è¯çš„æ¶ˆæ¯åˆ—è¡¨
            # - temperatureï¼šæ§åˆ¶è¾“å‡ºéšæœºæ€§
            # - stream=Trueï¼šå¼€å¯æµå¼è¾“å‡ºï¼Œä¾¿äºè¾¹æ¥æ”¶è¾¹æ¸²æŸ“
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=temperature,
                stream=True,
            )
            # å¤„ç†æµå¼å“åº”ï¼š
            # - æœåŠ¡ç«¯ä¼šæŒç»­æ¨é€ deltaï¼ˆå¢é‡ï¼‰ç‰‡æ®µ
            # - æœ‰äº›ç‰‡æ®µçš„ content å¯èƒ½æ˜¯ Noneï¼Œå› æ­¤ä½¿ç”¨ â€œor ''â€ å…œåº•
            # - ä½¿ç”¨ print(..., end='', flush=True) å³æ—¶åœ¨ç»ˆç«¯è¾“å‡º
            # å¤„ç†æµå¼å“åº”
            print("âœ… å¤§è¯­è¨€æ¨¡å‹å“åº”æˆåŠŸ:")
            collected_content = []
            for chunk in response:
                content = chunk.choices[0].delta.content or ""
                print(content, end="", flush=True)
                collected_content.append(content)
            print()  # åœ¨æµå¼è¾“å‡ºç»“æŸåæ¢è¡Œ
            return "".join(collected_content)

        except Exception as e:
            # å¼‚å¸¸æ•è·ï¼šåŒ…å«ç½‘ç»œé”™è¯¯ã€é‰´æƒå¤±è´¥ã€é…ç½®é”™è¯¯ç­‰
            print(f"âŒ è°ƒç”¨LLM APIæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return None

# --- å®¢æˆ·ç«¯ä½¿ç”¨ç¤ºä¾‹ ---
if __name__ == '__main__':
    try:
        # åˆ›å»ºå®¢æˆ·ç«¯å®ä¾‹ï¼š
        # - è‹¥æœªæ˜¾å¼ä¼ å…¥å‚æ•°ï¼Œå°†ä½¿ç”¨ç¯å¢ƒå˜é‡ï¼ˆLLM_MODEL_ID / LLM_API_KEY / LLM_BASE_URL / LLM_TIMEOUTï¼‰
        # - è¯·ç¡®ä¿ .env ä¸­å·²é…ç½®å¿…è¦ä¿¡æ¯
        llmClient = HelloAgentsLLM()
        
        # æ„é€ ç¤ºä¾‹æ¶ˆæ¯ï¼š
        # - system æŒ‡ä»¤ç”¨äºè®¾å®šåŠ©æ‰‹çš„è§’è‰²æˆ–è¡Œä¸ºå‡†åˆ™
        # - user æ¶ˆæ¯ä¸ºç”¨æˆ·è¾“å…¥
        exampleMessages = [
            {"role": "system", "content": "You are a helpful assistant that writes Python code."},
            {"role": "user", "content": "å†™ä¸€ä¸ªå¿«é€Ÿæ’åºç®—æ³•"}
        ]
        
        print("--- è°ƒç”¨LLM ---")
        responseText = llmClient.think(exampleMessages)
        if responseText:
            print("\n\n--- å®Œæ•´æ¨¡å‹å“åº” ---")
            print(responseText)

    except ValueError as e:
        # å½“å…³é”®é…ç½®ç¼ºå¤±æ—¶ï¼Œä¼šåœ¨åˆå§‹åŒ–é˜¶æ®µæŠ›å‡º ValueError
        print(e)
